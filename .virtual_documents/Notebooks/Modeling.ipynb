


#imports
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import geopandas as gpd
import math
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc
from sklearn.tree import plot_tree
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.linear_model import LassoCV, LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.metrics import roc_auc_score
from sklearn.metrics import f1_score, recall_score, precision_score
from sklearn.neighbors import KNeighborsClassifier

color = '#5D7963'
#warnings
import warnings
warnings.filterwarnings("ignore")


#reading the data
county_aggr = pd.read_csv('../csv_data/county_aggr.csv')


county_aggr.head(2)


county_aggr = county_aggr.loc[:, ~county_aggr.columns.str.contains('^Unnamed')]


county_aggr.head(2)


county_aggr.columns


X = county_aggr.drop(['State', 'County', 'is_food_desert', 'LowIncomeTracts', 'LILATracts_1And10', 'LALOWI1_10'], axis=1)
y = county_aggr['is_food_desert']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)





# Selecting numeric features
numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns

# Selecting categorical features
categorical_features = X_train.select_dtypes(include=['object']).columns



numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])


categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])


preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])


# Define the model pipeline with imputer
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])


#fit the model
model.fit(X_train, y_train)


# Preprocess the training and testing data using the preprocessor defined earlier
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)


# Standardizing numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_processed)
X_test_scaled = scaler.transform(X_test_processed)


# Random Forest Feature Importance
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_scaled, y_train)


# Univariate Feature Selection
selector = SelectKBest(score_func=f_classif, k=10)
X_train_selected = selector.fit_transform(X_train_scaled, y_train)
selected_features_indices = selector.get_support(indices=True)
selected_features = X_train.columns[selected_features_indices]


selected_features


# Lasso Regularization
lasso = LassoCV(cv=5, random_state=42)
lasso.fit(X_train_scaled, y_train)


# Feature Importance Plot for Lasso Regularization
plt.figure(figsize=(10, 6))

# Calculate feature importance using absolute coefficients of Lasso
importance_lasso = pd.Series(np.abs(lasso.coef_), index=X_train.columns)

# Select top 10 features with largest absolute coefficients
top_10_importance_lasso = importance_lasso.nlargest(10)

# Create horizontal bar plot
top_10_importance_lasso.plot(kind='barh', color='skyblue')

# Add title and labels
plt.title('Top 10 Features Importance - Lasso Regularization', fontsize=14)
plt.xlabel('Absolute Coefficient', fontsize=12)
plt.ylabel('Feature', fontsize=12)

# Add grid for better readability
plt.grid(axis='x', linestyle='--', alpha=0.7)

# Invert y-axis for better visualization
plt.gca().invert_yaxis()

# Show the plot
plt.show()


# Recursive Feature Elimination (RFE) #Ref: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html
logreg = LogisticRegression(max_iter=10000)
rfe = RFE(estimator=logreg, n_features_to_select=10, step=1)
rfe.fit(X_train_scaled, y_train)


# Feature Ranking from RFE
rfe_ranking = pd.Series(rfe.ranking_, index=X_train.columns)
selected_features_rfe = rfe_ranking[rfe_ranking == 1].index


importance_rf = rf.feature_importances_
importance_rf_series = pd.Series(importance_rf, index=X_train.columns)

# Get indices of top 10 features based on their importance
top_10_indices = np.argsort(importance_rf)[-10:]

# Extract top 10 feature names from X_train.columns
top_10_features = X_train.columns[top_10_indices]

# Output selected features from different techniques
print("Selected features using Random Forest Feature Importance:")
print(top_10_features)
print("\nSelected features using Univariate Feature Selection:")
print(selected_features)
print("\nSelected features using Lasso Regularization:")
print(importance_lasso.nlargest(10))
print("\nSelected features using Recursive Feature Elimination (RFE):")
print(selected_features_rfe)





model = LinearSVC(penalty='l2', loss='hinge')


# Training on SVM
print("TRAIN on SVM")
roc_auc_train = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
accuracy_train = cross_val_score(model, X_train, y_train, cv=5).mean()
f1_train = cross_val_score(model, X_train, y_train, cv=5, scoring='f1').mean()
print("ROC_AUC score (Training): ", roc_auc_train)
print("Accuracy score (Training): ", accuracy_train)
print("F1 score (Training): ", f1_train)

# Testing on SVM
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_pred_proba = model.decision_function(X_test)

print("\nTEST on SVM")
roc_auc_test = roc_auc_score(y_test, y_pred_proba)
accuracy_test = accuracy_score(y_test, y_pred)
f1_test = f1_score(y_test, y_pred)
recall_test = recall_score(y_test, y_pred)
precision_test = precision_score(y_test, y_pred)

print("ROC_AUC score (Test): ", roc_auc_test)
print("Accuracy score (Test): ", accuracy_test)
print("F1 score (Test): ", f1_test)
print("Recall score (Test): ", recall_test)
print("Precision score (Test): ", precision_test)





# KNN
print("KNN")
print()
model = KNeighborsClassifier(n_neighbors=5)

# Train stats
print("TRAIN on KNN")
roc_auc_train = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
accuracy_train = cross_val_score(model, X_train, y_train, cv=5).mean()
f1_train = cross_val_score(model, X_train, y_train, cv=5, scoring='f1').mean()
recall_train = cross_val_score(model, X_train, y_train, cv=5, scoring='recall').mean()
precision_train = cross_val_score(model, X_train, y_train, cv=5, scoring='precision').mean()

print("ROC_AUC score (train): ", roc_auc_train)
print("Accuracy score (train): ", accuracy_train)
print("F1 score (train): ", f1_train)
print("Recall score (train): ", recall_train)
print("Precision score (train): ", precision_train)

# Predict and get test stats
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_predproba_knn = model.predict_proba(X_test)
fpr_knn, tpr_knn, thresholds = roc_curve(y_test.values, y_predproba_knn[:,1])

print()
print("TEST on KNN")
roc_auc_test = roc_auc_score(y_test, y_pred)
accuracy_test = accuracy_score(y_test, y_pred)
f1_test = f1_score(y_test, y_pred)
recall_test = recall_score(y_test, y_pred)
precision_test = precision_score(y_test, y_pred)

print("ROC_AUC score (test): ", roc_auc_test)
print("Accuracy score (test): ", accuracy_test)
print("F1 score (test): ", f1_test)
print("Recall score (test): ", recall_test)
print("Precision score (test): ", precision_test)



# Plot figure
plt.figure(figsize=(10, 6))

metrics = ['ROC_AUC', 'Accuracy', 'F1', 'Recall', 'Precision']
train_scores = [roc_auc_train, accuracy_train, f1_train, recall_train, precision_train]
test_scores = [roc_auc_test, accuracy_test, f1_test, recall_test, precision_test]

bar_width = 0.35
index = range(len(metrics))

plt.bar(index, train_scores, width=bar_width, color='skyblue', alpha=0.7, label='Train')
plt.bar([i + bar_width for i in index], test_scores, width=bar_width, color='orange', alpha=0.7, label='Test')

plt.xlabel('Metrics', fontsize=12)
plt.ylabel('Scores', fontsize=12)
plt.title('Performance Metrics Comparison for KNN', fontsize=14)
plt.xticks([i + bar_width/2 for i in index], metrics)
plt.legend()
plt.tight_layout()
plt.savefig('../Images/performancem_metrics_KNN.png', dpi=200, bbox_inches='tight')

plt.show()





#initialize
model = GradientBoostingClassifier()
print("GRADIENT BOOSTING")
print()

print("TRAIN on GB")
print("ROC_AUC score: ", cross_val_score(model,X_train,y_train,cv=5,scoring='roc_auc').mean())
print("Accuracy score: ", cross_val_score(model,X_train,y_train,cv=5).mean())
print("f1 score: ", cross_val_score(model,X_train,y_train,cv=5,scoring='f1').mean())

model.fit(X_train,y_train)
y_pred = model.predict(X_test)

print()
print("TEST on GB")
print("ROC_AUC score: ", roc_auc_score(y_test,y_pred))
print("Accuracy score: ", accuracy_score(y_test,y_pred))
print("f1 score: ", f1_score(y_test,y_pred))
print("recall score: ", recall_score(y_test,y_pred))
print("precision score: ", precision_score(y_test,y_pred))


# Train on GB
print("TRAIN on GB")
roc_auc_train = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc').mean()
accuracy_train = cross_val_score(model, X_train, y_train, cv=5).mean()
f1_train = cross_val_score(model, X_train, y_train, cv=5, scoring='f1').mean()
y_pred_train = model.fit(X_train, y_train).predict(X_train)
recall_train = recall_score(y_train, y_pred_train)
precision_train = precision_score(y_train, y_pred_train)

print("ROC_AUC score (Train):", roc_auc_train)
print("Accuracy score (Train):", accuracy_train)
print("F1 score (Train):", f1_train)
print("Recall score (Train):", recall_train)
print("Precision score (Train):", precision_train)

# Test on GB
print()
print("TEST on GB")
y_pred_test = model.predict(X_test)
roc_auc_test = roc_auc_score(y_test, y_pred_test)
accuracy_test = accuracy_score(y_test, y_pred_test)
f1_test = f1_score(y_test, y_pred_test)
recall_test = recall_score(y_test, y_pred_test)
precision_test = precision_score(y_test, y_pred_test)

print("ROC_AUC score (Test):", roc_auc_test)
print("Accuracy score (Test):", accuracy_test)
print("F1 score (Test):", f1_test)
print("Recall score (Test):", recall_test)
print("Precision score (Test):", precision_test)





# Define preprocessing

#numerial data
numeric_features = X.select_dtypes(include=['int64', 'float64']).columns

#categorical data
categorical_features = X.select_dtypes(include=['object']).columns


#numeric transformer
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])


#categorical transformer
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='conatant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])


#preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)


#Define the model
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])


#fit the model
model.fit(X_train, y_train)


#predict
y_pred = model.predict(X_test)
y_pred


#evaluate
accuracy_score(y_test, y_pred)


print(classification_report(y_test, y_pred))


#Receiver Operating Characteristic (ROC) curve and compute the Area Under the Curve (AUC) score for a binary classification model.


#This line computes the False Positive Rate (FPR), True Positive Rate (TPR), and decision thresholds for different probability cutoffs.
#returns the predicted probabilities of the positive class from the model for the test set.
#Area Under the ROC Curve (ROC AUC) using the FPR and TPR 
fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc = auc(fpr, tpr)


# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right", fontsize=10)
plt.grid(True, linestyle='--', alpha=0.5)
plt.tick_params(axis='both', which='major', labelsize=10)
plt.savefig('../Images/ROC_curve.png', dpi=200, bbox_inches='tight')

plt.show()


#extracts the feature importances from the trained classifier component of the model.
importances = model.named_steps['classifier'].feature_importances_
indices = np.argsort(importances)[::-1]


#print the feature ranking
print("Feature ranking: ")
for f in range(X_train.shape[1]):
    print(f"{f+1}. feature {X_train.columns[indices[f]]} ({importances[indices[f]]})")


#plotting the features
feature_importances = model.named_steps['classifier'].feature_importances_
indices = np.argsort(feature_importances)[::-1]
names = [X.columns[i] for i in indices]

import matplotlib.cm as cm

# Define a colormap
colormap = cm.get_cmap('viridis')

# Plotting with gradient colors
plt.figure(figsize=(10, 7))
plt.title("Feature Importance")

# Plot horizontal bar chart with gradient colors
bars = plt.barh(range(X.shape[1]), feature_importances[indices], color=colormap(np.linspace(0, 1, len(indices))))
plt.yticks(range(X.shape[1]), names, rotation=0)
sm = cm.ScalarMappable(cmap=colormap)
sm.set_array(feature_importances[indices])
cbar = plt.colorbar(sm)
cbar.set_label('Importance')
plt.savefig('../Images/feature_importance.png', dpi=200, bbox_inches='tight')
plt.show();


scores = cross_val_score(model, X, y, cv=5)
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))





#Decision tree for random forest classifier

rfc = model.named_steps['classifier']
estimator = rfc.estimators_[0]


#plot
plt.figure(figsize=(20, 10))
plot_tree(estimator,
         filled=True,
         feature_names=X.columns,
         class_names=['Not Food Desert', 'Food Desert'],
         max_depth=3,
         fontsize=10,  # Adjust font size for better readability
          label="all",  # Show all node labels
          impurity=False,  # Hide impurity information
          proportion=True,  # Show proportion of samples for each class
          precision=2,  # Set precision for class proportions
          rounded=True,  # Round the corners of nodes
          node_ids=True)  # Show node IDs 
plt.title('Decision Tree for Random forest Model')
plt.savefig('../Images/decisiontree_rf.png', dpi=200, bbox_inches='tight')
plt.show();





shapefile_path = '../Data/geodata/cb_2018_us_county_5m.shp'


gdf = gpd.read_file(shapefile_path)


# Displaying the first few rows of the GeoDataFrame
print(gdf.head())


# Plotting the GeoDataFrame
gdf.plot()


gdf.head(5)


#merging geodf and county_aggr


#Formatting the county name to match the GeoDataFrame
county_aggr['CensusTract'] = county_aggr['CensusTract'].astype(str)

# Extract and generate the FIPS code (the first 5 digits of CensusTract)
county_aggr['FIPS'] = county_aggr['CensusTract'].str[:5]


# Merging on GEOID and FIPS
merged_gdf = gdf.merge(county_aggr, left_on='GEOID', right_on='FIPS', how='left')

merged_gdf.head()


#saving this df but not using it
merged_gdf.to_csv('../csv_data/merged_geo_county.csv')


# Plotting tests: PovertyRate by County
fig, ax = plt.subplots(1, 1, figsize=(15, 10))
merged_gdf.plot(column='PovertyRate', ax=ax, legend=True)
plt.show()


#Ref: https://geopandas.org/en/stable/docs/user_guide/mapping.html

#Variable to store unique states
states = merged_gdf['State'].unique()

# Calculate grid size
n = len(states)
cols = 3  # Set number of columns in the grid
rows = math.ceil(n / cols)  # Calculate required rows

fig, axes = plt.subplots(rows, cols, figsize=(20, rows * 6), constrained_layout=True)
axes = axes.flatten() 

for i, state in enumerate(states):
    state_gdf = merged_gdf[merged_gdf['State'] == state]
    
    # Check if the state_gdf is empty, continue to the next state if true
    if state_gdf.empty:
        continue
    
    state_gdf.plot(column='PovertyRate', ax=axes[i], legend=True,
                   missing_kwds={
                       "color": "lightgrey",
                       "edgecolor": "red",
                       "hatch": "///",
                       "label": "Missing values"},
                   legend_kwds={'label': "Poverty Rate",
                                'orientation': "horizontal"})
    axes[i].set_title(state)
    
for j in range(i + 1, rows * cols):
    axes[j].axis('off')
plt.savefig('../Images/geopandas_state.png', dpi=200, bbox_inches='tight')
plt.show()



